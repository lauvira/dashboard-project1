# -*- coding: utf-8 -*-
"""Proyek_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hRYkMVY5F3NXutKFNxm2K5xfdmWJNAG_

# Proyek Analisis Data: E-Commerce Public Dataset
- Nama: **Laurensia Vira Farindra**
- Email: **laurensiavira@gmail.com**
- Id Dicoding: **lauvira**

## Menentukan Pertanyaan Bisnis

Berikut pertanyaan bisnis yang akan dicari jawabannya:

1) Bagaimana perkembangan performa penjualan di platform e-commerce dari waktu ke waktu?

2) Pada wilayah mana saja pelanggan paling banyak berada?

## Menyiapkan Semua Library yang Dibutuhkan
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import urllib
!pip install unidecode
import unidecode
import matplotlib.image as mpimg

"""## Data Wrangling

### Gathering Data

Pertama-tama, akan dilakukan import data lalu penggabungan seluruh data.

Penggunaan satu file data yang mencakup seluruh data akan mempermudah dalam melakukan proses selanjutnya.
"""

customers = pd.read_csv('customers_dataset.csv')
customers.head()

geolocation = pd.read_csv('geolocation_dataset.csv')
geolocation.head()

order_items = pd.read_csv('order_items_dataset.csv')
order_items.head()

order_pay = pd.read_csv('order_payments_dataset.csv')
order_pay.head()

order_rev = pd.read_csv('order_reviews_dataset.csv')
order_rev.head()

orders = pd.read_csv('orders_dataset.csv')
orders.head()

product_cat = pd.read_csv('product_category_name_translation.csv')
product_cat.head()

products = pd.read_csv('products_dataset.csv')
products.head()

sellers = pd.read_csv('sellers_dataset.csv')
sellers.head()

"""### Assessing Data

Tahap *pre-processing* selanjutnya adalah pengecekan adanya data *null* dan data duplikat.
"""

print('\nData null customers:\n', customers.isnull().sum())
print('\nData null geolocation:\n', geolocation.isnull().sum())
print('\nData null order items:\n', order_items.isnull().sum())
print('\nData null order payments:\n', order_pay.isnull().sum())
print('\nData null order reviews:\n', order_rev.isnull().sum())
print('\nData null orders:\n', orders.isnull().sum())
print('\nData null product category:\n', product_cat.isnull().sum())
print('\nData null products:\n', products.isnull().sum())
print('\nData null sellers:\n', sellers.isnull().sum())

print('Data duplikat customers:', customers.duplicated().sum())
print('Data duplikat geolocation:', geolocation.duplicated().sum())
print('Data duplikat order items:', order_items.duplicated().sum())
print('Data duplikat order payments:', order_pay.duplicated().sum())
print('Data duplikat order reviews:', order_rev.duplicated().sum())
print('Data duplikat orders:', orders.duplicated().sum())
print('Data duplikat product category:', product_cat.duplicated().sum())
print('Data duplikat products:', products.duplicated().sum())
print('Data duplikat sellers:', sellers.duplicated().sum())

"""Berdasarkan proses pengecekan di atas, dapat dilihat bahwa terdapat data *null* atau kekosongan data pada:
1. Data `order_reviews` kolom *title* dan *message*.
2. Data `orders` kolom *order_approved_at*, *order_delivered_carrier_date*, *order_delivered_customer_date*.
3. Data `products` kolom *product_category_name*, *product_name_lenght*, *product_description_lenght*, dan *product_photos_qty*.

Sedangkan, hanya terdapat duplikasi data pada `geolocation`.

### Cleaning Data

Proses *cleaning data* yang dilakukan adalah pengisian kolom yang memiliki data *null* pada `order_reviews` serta *dropping* pada `orders`. Tidak dilakukan drop data duplikat karena jika ditelaah kembali, value pada data `geolocation` memang memungkinkan untuk berduplikasi (value SP/Sao Paulo).
"""

#Mengidentifikasi letak null pada data
order_rev[order_rev.review_comment_title.isna()]

#Mengidentifikasi letak null pada data
order_rev[order_rev.review_comment_message.isna()]

#Mengisi sel kosong dengan No Comment, dengan asumsi bahwa customer tidak melakuan review.
#(Terlihat pula dari value order_status yang canceled/dibatalkan)
order_rev.fillna(value="No Comment", inplace=True)

#Mengecek kembali apakah seluruh kolom telah terisi
print('\nData null order reviews:\n', order_rev.isnull().sum())

#Mengidentifikasi letak null pada data
orders[orders.order_approved_at.isna()]

orders.dropna(axis=0, inplace=True)

#Mengecek kembali apakah seluruh kolom telah terisi
print('\nData null orders:\n', orders.isnull().sum())

orders.info()

"""Diperkirakan bahwa sisa data *non-null* cukup untuk melakukan analisis selanjutnya.

## Exploratory Data Analysis (EDA)

### Explore **customers** dan **orders**

Akan di-*explore* persebaran geografis customer, preferensi tipe pembayaran, durasi pengiriman, serta status order.
"""

#Mengecek apakah customer yang dianalisis seluruhnya unik.
#Jika True, maka diasumsikan seluruh customer adalah orang yang berbeda.
customers.customer_id.is_unique

#Mengetahui distribusi customers berdasarkan kotanya serta mengurutkan dari paling banyak.
customers.groupby(by="customer_city").customer_id.nunique().sort_values(ascending=False)

"""Customer terbanyak berada di kota Sao Paulo."""

#Mengetahui distribusi customers berdasarkan negara bagian.
customers.groupby(by="customer_state").customer_id.nunique().sort_values(ascending=False)

"""Customer terbanyak terdapat pada negara bagian Sao Paulo."""

#Mengetahui tipe pembayaran untuk pemesanan yang dilakukan.
order_pay.groupby(by="payment_type").order_id.nunique().sort_values(ascending=False)

"""Tipe pembayaran yang menjadi favorit customer adalah dengan menggunakan kartu kredit."""

#Mengubah format value menjadi datetime untuk mempermudah analisis
orders["order_delivered_customer_date"] = pd.to_datetime(orders["order_delivered_customer_date"])
orders["order_delivered_carrier_date"] = pd.to_datetime(orders["order_delivered_carrier_date"])

#Menghitung selisih waktu pengiriman untuk setiap pesanan dalam satuan hari.
#Memasukkan hasil selisih tersebut ke dalam kolom baru "delivery_duration"
delivery_duration = orders["order_delivered_customer_date"]-orders["order_delivered_carrier_date"]
delivery_duration = delivery_duration.apply(lambda x: x.total_seconds()) #Mengubah ke satuan detik
orders["delivery_duration"] = round(delivery_duration/86400) #Mengubah ke satuan hari (dibulatkan)

orders.sample(10)

orders.delivery_duration.hist()

"""Berikut grafik dari durasi pengiriman barang pada *e-commerce*.

**Merge customers & orders**
"""

#Untuk analisis berikutnya, data customers dan orders perlu digabungkan terlebih dahulu.
cust_and_orders = pd.merge(
    left=customers,
    right=orders,
    how="left",
    left_on="customer_id",
    right_on="customer_id"
)
cust_and_orders.head()

cust_and_orders.groupby(by="order_status").order_id.nunique().sort_values(ascending=False)

"""Pada dataset ini, sebagian besar order telah memiliki status *delivered* atau telah dikirim. Sisanya, terdapat order yang masih dalam proses *approval* hingga pengiriman. Ada pula beberapa order yang dibatalkan.  """

cust_and_orders.groupby(by="customer_city").order_id.nunique().sort_values(ascending=False)

"""Terlihat bahwa hasilnya sama seperti saat kolom ***customer_id*** yang digunakan."""

cust_and_orders.groupby(by="customer_state").order_id.nunique().sort_values(ascending=False)

"""Terlihat bahwa hasilnya sama seperti saat kolom ***customer_id*** yang digunakan.

**Merge order_pay & order_rev**
"""

#Untuk analisis berikutnya, data order_pay dan order_rev perlu digabungkan terlebih dahulu.
order_payrev = pd.merge(
    left=order_pay,
    right=order_rev,
    how="left",
    left_on="order_id",
    right_on="order_id"
)
order_payrev.head()

#Mengetahui urutan besaran pembayaran beserta keterangan kolom lain secara lengkap.
order_payrev.sort_values(by="payment_value", ascending=False)

#Mengetahui besaran pembayaran paling kecil dan paling besar pada setiap tipe pembayaran.
order_payrev.groupby(by="payment_type").agg({
    "order_id": "nunique",
    "payment_value":  ["min", "max"]
})

"""**Merge cust_orders_df & order_payrev**"""

#mendapatkan gabungan data yang berkaitan dengan customers dan orders
all_customers_info = pd.merge(
    left=cust_and_orders,
    right=order_payrev,
    how="left",
    left_on="order_id",
    right_on="order_id"
)
all_customers_info.head()

"""### Explore **order_items** dan **sellers**"""

item_seller = pd.merge(
    left=order_items,
    right=sellers,
    how="left",
    left_on="seller_id",
    right_on="seller_id"
)
item_seller.head()

item_seller.groupby(by="seller_city").order_id.nunique().sort_values(ascending=False).head(10)

"""Terlihat bahwa order paling banyak dilakukan pada seller atau penjual yang berada di kota Sao Paulo."""

item_seller.groupby(by="seller_city").product_id.nunique().sort_values(ascending=False).head(10)

"""Berikut persebaran jumlah produk menurut kota. Terdapat perbedaan urutan kota jika dibandingkan dengan yang menggunakan *order_id*.

### Explore **products**
"""

product_info = pd.merge(
    left=products,
    right=product_cat,
    how="left",
    left_on="product_category_name",
    right_on="product_category_name"
)
product_info.head()

product_info.groupby(by="product_category_name_english").product_id.nunique().sort_values(ascending=False).head(10)

"""Terlihat kategori produk yang paling banyak dibeli. Dalam kasus ini, kategori produk *bed_bath_table* (kasur, peralatan mandi, meja) adalah yang tertinggi.

**Merge item_seller & product_info**
"""

all_product_info = pd.merge(
    left=product_info,
    right=item_seller,
    how="left",
    left_on="product_id",
    right_on="product_id"
)
all_product_info.head()

#Mengurutkan harga produk dari yang tertinggi sekaligus menampilkan seluruh kolom.
all_product_info.sort_values(by="price", ascending=False)

#Mengetahui harga produk terendah dan tertinggi pada masing-masing kategori produk.
all_product_info.groupby(by="product_category_name_english").agg({
    "order_id": "nunique",
    "price":  ["min", "max"]
})

"""### Explore **geolocation**"""

#Mengubah value pada geolocation_city dengan menghilangkan spasi, mengubah dalam
#bentuk lowercase, serta menghapus special characters.
def edit_string(column):
    column_space = ' '.join(column.split())
    return unidecode.unidecode(column_space.lower())

geolocation['geolocation_city'] = geolocation['geolocation_city'].apply(edit_string)

geolocation.groupby('geolocation_zip_code_prefix').size().sort_values(ascending=False)

#Menunjukkan baris yang memiliki zip code prefix tertentu,
#misalnya 24230 (bisa diubah).
geolocation[geolocation['geolocation_zip_code_prefix'] == 24230].head()

"""### Explore **All Data**

**Merge all data**
"""

all_data = pd.merge(
    left= all_customers_info,
    right= all_product_info,
    how="left",
    left_on="order_id",
    right_on="order_id"
)
all_data.head()

#Mengetahui total jumlah harga dan jumlah ongkos kirim yang dibeli, dan disesuaikan
#dengan kota customer dan kategori produk. (Preferensi pembelian berdasarkan kota)
all_data.groupby(by=["customer_city", "product_category_name_english"]).agg({
    "price": "sum",
    "freight_value": "sum"
})

"""Dari hasil tersebut, kita ambil contoh untuk customer dari abadia dos dourados. Di kota tersebut, customer membeli barang dengan kategori *buku_general_interest*, *cool_stuff*, dan *sports_leisure* dengan total harga produk dan ongkos kirim tertera."""

all_data.groupby(by=["customer_state", "product_category_name_english"]).agg({
    "price": "sum",
    "freight_value": "sum"
})

"""Dilakukan hal yang mirip dengan sebelumnya, namun berdasarkan customer di negara bagian."""

#Mengetahui urutan total order serta total pembayaran yang dilakukan customer di tiap negara bagian.
all_data.groupby(by="customer_state").agg({
    "order_id": "nunique",
    "payment_value": "sum"
}).sort_values(by="payment_value", ascending=False)

#Mengetahui score review terendah dan tertinggi yang didapatkan suatu kategori poduk.
all_data.groupby(by="product_category_name_english").agg({
    "order_id": "nunique",
    "review_score":  ["min", "max"]
})

"""Terlihat bahwa sebagian skor terendah adalah 1 dan skor tertinggi adalah 5. Dapat diperkirakan adanya keberagaman dalam *review*, karena range skor-nya juga 1 sampai 5.

### Convert all_data to .csv

Setelah semua data digabung, akhirnya disimpan ke dalam format .csv untuk dapat digunakan pada analisis selanjutnya.
"""

all_data.to_csv('/content/all_data.csv', index=False)

"""## Visualization & Explanatory Analysis

### Pertanyaan 1 : Bagaimana perkembangan performa penjualan di platform *e-commerce* dari waktu ke waktu?
"""

all_data_df = pd.read_csv('all_data.csv')
all_data_df.head()

#Mengubah value menjadi datetime untuk analisis selanjutnya
all_data_df["order_approved_at"] = pd.to_datetime(all_data_df["order_approved_at"])

#Mengelompokkan pesanan berdasarkan bulan persetujuan pesanan serta
#menghitung jumlah pesanan unik dalam setiap bulannya.
monthly_df = all_data_df.resample(rule='M', on='order_approved_at').agg({
    "order_id": "nunique",
})

monthly_df.index = monthly_df.index.strftime('%B') #Mengubah format order_approved_at menjadi Tahun-Bulan
monthly_df = monthly_df.reset_index() #Mengubah menjadi kolom data biasa
monthly_df.sample(15)

#Mengurutkan data berdasarkan jumlah pesanan dan menghapus duplikasi bulan, dengan menyimpan bulan dengan tahun tertinggi.
#Didapatkan data penjualan bulanan tahun 2018.
monthly_df = monthly_df.sort_values('order_id').drop_duplicates('order_approved_at', keep='last')

monthly_df.head()

#Mapping untuk visualisasi
month_mapping = {
    "January": 1,
    "February": 2,
    "March": 3,
    "April": 4,
    "May": 5,
    "June": 6,
    "July": 7,
    "August": 8,
    "September": 9,
    "October": 10,
    "November": 11,
    "December": 12
}

monthly_df["month_numeric"] = monthly_df["order_approved_at"].map(month_mapping)
monthly_df = monthly_df.sort_values("month_numeric")
monthly_df = monthly_df.drop("month_numeric", axis=1)

plt.figure(figsize=(10, 5))
plt.plot(
    monthly_df["order_approved_at"],
    monthly_df["order_id"],
    marker='o',
    linewidth=2,
    color="#068DA9"
)
plt.title("Jumlah Order Tiap Bulan pada Tahun 2018", loc="center", fontsize=20)
plt.xticks(fontsize=10, rotation=25)
plt.yticks(fontsize=10)
plt.show()

"""Terlihat pada grafik diatas bahwa terjadi penurunan order yang signifikan pada bulan September dan peningkatan order signifikan pada bulan November.

### Pertanyaan 2 : Pada wilayah mana saja pelanggan paling banyak berada?

#### Berdasarkan customer_state
"""

#Menghitung jumlah customer berdasarkan negara bagian
bystate_df = all_data.groupby(by="customer_state").customer_id.nunique().reset_index()
bystate_df.rename(columns={
    "customer_id": "customer_count"
}, inplace=True)
bystate_df.head()

plt.figure(figsize=(12, 6))

most_common_state = bystate_df.loc[bystate_df['customer_count'].idxmax(), 'customer_state']

bystate_df = bystate_df.sort_values(by='customer_count', ascending=False)

sns.barplot(x='customer_state',
            y='customer_count',
            data=bystate_df,
            palette=["#FF0000" if state == most_common_state else "#D3D3D3" for state in bystate_df['customer_state']]
            )

plt.title("Jumlah Customer dari Negara Bagian", fontsize=15)
plt.xlabel("Negara Bagian")
plt.ylabel("Jumlah Customer")
plt.xticks(fontsize=10)
plt.show()

"""Dari hasil grafik di atas, dapat dilihat bahwa sebagian besar customer berada di Sao Paulo. Perbedaan jumlah customer di Sao Paulo dan wilayah lainnya cukup signifikan.

#### Berdasarkan customer_city
"""

#Menghitung jumlah customer berdasarkan kota
bycity_df = all_data.groupby(by="customer_city").customer_id.nunique().reset_index()
bycity_df.rename(columns={
    "customer_id": "customer_count"
}, inplace=True)
bycity_df.head()

bycity_df = all_data['customer_city'].value_counts().head(10)

plt.figure(figsize=(12, 6))

most_common_city = bycity_df.idxmax()

bycity_df = bycity_df.sort_values(ascending=False)

sns.barplot(x=bycity_df.index,
            y=bycity_df.values,
            palette=["#FF0000" if city == most_common_city else "#D3D3D3" for city in bycity_df.index]
            )

plt.title("Jumlah Customer dari Kota", fontsize=15)
plt.xlabel("Kota")
plt.ylabel("Jumlah Customer")
plt.xticks(rotation=45, fontsize=10)
plt.show()

"""Begitu pula berdasarkan kota, Sao Paulo memiliki customer terbanyak.

## Conclusion

1) Bagaimana perkembangan performa penjualan di platform e-commerce dari waktu ke waktu?
> Performa e-commerce yang diteliti adalah performa pada tahun 2018. Berdasarkan grafik, jumlah order pada bulan Januari hingga Agustus terlihat cukup stabil dan cenderung menurun walaupun tidak signifikan. Namun, terjadi penurunan besar pada bulan September. Kenaikan pesat terjadi pada bulan November, dimana pada bulan ini terjadi jumlah order tertinggi. Terakhir, terjadi penurunan kembali pada bulan Desember. Perlu diselidiki kembali faktor eksternal apa yang menyebabkan hal ini dapat terjadi.

2) Pada wilayah mana saja pelanggan paling banyak berada?
> Berdasarkan grafik yang telah dihasilkan, São Paulo memiliki jumlah pelanggan atau customer yang jumlahnya berbeda sangat signifikan jika dibandingkan dengan negara bagian atau kota lain. Hal ini mungkin dikarenakan São Paulo adalah kota sekaligus negara bagian yang paling padat di Brazil. Pada urutan ke-2, terdapat Rio de Janeiro yang merupakan kota terpadat ke-2 pula.
"""